{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e3e7a0",
   "metadata": {},
   "source": [
    "# Personalized Healthcare Recommendations\n",
    "\n",
    "This notebook implements a machine learning model to provide personalized healthcare recommendations based on individual patient data. The goal is to improve patient outcomes by leveraging data-driven insights to offer personalized advice.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "1. **Problem Understanding**: Provide personalized healthcare recommendations to patients based on their health data, medical history, lifestyle, and other relevant factors.\n",
    "2. **Dataset**: Patient healthcare data including demographics, medical history, lab results, and treatment responses\n",
    "3. **Methodology**: Machine learning techniques to analyze patient data and generate actionable insights\n",
    "4. **Output**: Personalized healthcare recommendations for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e5347-73a8-412e-8a5f-0cc95ccf7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- imports ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7d9d5-f400-4c39-ae44-ab503d9a82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- load dataset ----------\n",
    "# Load the patient healthcare dataset\n",
    "csv_path = Path('../data/raw/patient_data.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167b94f-7305-4f0e-93b3-0bc679177b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- data exploration ----------\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Number of patients: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3295ff4-6932-4a01-9d4e-f6e3b83821e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- exploratory data analysis ----------\n",
    "# Distribution of target variable (Treatment Response)\n",
    "plt.figure(figsize=(10, 6))\n",
    "treatment_response_counts = df['Treatment Response'].value_counts()\n",
    "bars = plt.bar(treatment_response_counts.index, treatment_response_counts.values, \n",
    "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "plt.title('Distribution of Treatment Responses', fontsize=16)\n",
    "plt.xlabel('Treatment Response', fontsize=12)\n",
    "plt.ylabel('Number of Patients', fontsize=12)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Treatment Response Distribution:\")\n",
    "print(treatment_response_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a8a91-3ac5-498f-9b33-20c12678cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Age'], bins=15, kde=True, color='skyblue')\n",
    "plt.title('Age Distribution of Patients', fontsize=16)\n",
    "plt.xlabel('Age (years)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAge Statistics:\")\n",
    "print(df['Age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58daf7aa-6828-4f77-aba4-0ef16f4981ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "gender_counts = df['Gender'].value_counts()\n",
    "plt.pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', \n",
    "        startangle=90, colors=['#FF9999', '#66B2FF', '#99FF99'])\n",
    "plt.title('Gender Distribution of Patients', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nGender Distribution:\")\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da9eb0-19d0-4381-bebe-074e9db1d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical conditions analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "medical_counts = df['Medical History'].value_counts()\n",
    "bars = plt.bar(range(len(medical_counts)), medical_counts.values)\n",
    "plt.title('Distribution of Medical Conditions', fontsize=16)\n",
    "plt.xlabel('Medical Condition', fontsize=12)\n",
    "plt.ylabel('Number of Patients', fontsize=12)\n",
    "plt.xticks(range(len(medical_counts)), medical_counts.index, rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMedical Conditions Distribution:\")\n",
    "print(medical_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03578e9a-c48d-498c-ae77-494afc109188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- data preprocessing ----------\n",
    "# Create a copy of the dataframe for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Normalize column names\n",
    "df_processed.columns = df_processed.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "\n",
    "# Display the cleaned column names\n",
    "print(\"Normalized column names:\")\n",
    "print(df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a8a91-3ac5-498f-9b33-20c12678cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- feature engineering ----------\n",
    "# Extract numerical values from vital signs\n",
    "def extract_vital_signs(vital_signs_str):\n",
    "    \"\"\"Extract systolic BP, diastolic BP, and heart rate from vital signs string\"\"\"\n",
    "    try:\n",
    "        # Example: \"BP: 130/85, HR: 72\"\n",
    "        bp_part = vital_signs_str.split('BP: ')[1].split(',')[0]\n",
    "        systolic, diastolic = map(int, bp_part.split('/'))\n",
    "        heart_rate = int(vital_signs_str.split('HR: ')[1])\n",
    "        return systolic, diastolic, heart_rate\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "# Apply the function to extract vital signs\n",
    "vital_data = df_processed['vital_signs'].apply(extract_vital_signs)\n",
    "df_processed['systolic_bp'] = [x[0] for x in vital_data]\n",
    "df_processed['diastolic_bp'] = [x[1] for x in vital_data]\n",
    "df_processed['heart_rate'] = [x[2] for x in vital_data]\n",
    "\n",
    "# Create age groups\n",
    "df_processed['age_group'] = pd.cut(df_processed['age'], \n",
    "                                   bins=[0, 30, 45, 60, 100], \n",
    "                                   labels=['Young Adult', 'Middle Adult', 'Older Adult', 'Senior'])\n",
    "\n",
    "# Create chronic condition indicator\n",
    "chronic_conditions = ['diabetes', 'hypertension', 'heart disease', 'asthma', 'copd', 'kidney']\n",
    "df_processed['has_chronic_condition'] = df_processed['medical_history'].str.lower().apply(\n",
    "    lambda x: any(condition in str(x) for condition in chronic_conditions)\n",
    ").astype(int)\n",
    "\n",
    "# Create family history indicator\n",
    "df_processed['family_history_indicator'] = (df_processed['family_history'] == 'Yes').astype(int)\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- Systolic BP, Diastolic BP, Heart Rate (extracted from vital signs)\")\n",
    "print(\"- Age groups\")\n",
    "print(\"- Chronic condition indicator\")\n",
    "print(\"- Family history indicator\")\n",
    "\n",
    "print(\"\\nDataset shape after feature engineering:\", df_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b2c3d4-e5f6-7890-g1h2-i3j4k5l6m7n8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- prepare features and target ----------\n",
    "# Define target variable\n",
    "target = 'treatment_response'\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = [\n",
    "    'age', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'recovery_time',\n",
    "    'gender', 'ethnicity', 'medical_history', 'age_group', \n",
    "    'has_chronic_condition', 'family_history_indicator'\n",
    "]\n",
    "\n",
    "# Create feature matrix and target vector\n",
    "X = df_processed[feature_columns]\n",
    "y = df_processed[target]\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "print(\"\\nFeatures used:\")\n",
    "for feature in feature_columns:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4g5h6i7j8k9-l0m1n2o3p4q5r6s7t8u9v0w1x2y3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- handle missing values ----------\n",
    "print(\"Missing values before imputation:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Separate numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical features: {numerical_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "\n",
    "# Impute missing values\n",
    "# For numerical features: use median\n",
    "for col in numerical_features:\n",
    "    X[col].fillna(X[col].median(), inplace=True)\n",
    "\n",
    "# For categorical features: use mode\n",
    "for col in categorical_features:\n",
    "    X[col].fillna(X[col].mode()[0] if not X[col].mode().empty else 'Unknown', inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(X.isnull().sum().sum(), \"total missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4a5b6c7d8e9f0g1h2i3j4k5l6m7n8o9p0q1r2s3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- encode categorical variables ----------\n",
    "# Create preprocessing pipelines\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "print(\"Preprocessing pipelines created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5c6d7e8f9g0h1i2j3k4l5m6n7o8p9q0r1s2t3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- split the data ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7f8g9h0i1j2k3l4m5n6o7p8q9r0s1t2u3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- model training ----------\n",
    "# Create a pipeline with preprocessing and Random Forest classifier\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f7g8h9i0j1k2l3m4n5o6p7q8r9s0t1u2v3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- model evaluation ----------\n",
    "# Make predictions\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=rf_pipeline.named_steps['classifier'].classes_, \n",
    "            yticklabels=rf_pipeline.named_steps['classifier'].classes_)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5g6h7i8j9k0l1m2n3o4p5q6r7s8t9u0v1w2x3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- feature importance ----------\n",
    "# Get feature names after preprocessing\n",
    "preprocessor = rf_pipeline.named_steps['preprocessor']\n",
    " \n",
    "# Get feature names for numerical features\n",
    "numerical_feature_names = numerical_features\n",
    "\n",
    "# Get feature names for categorical features (after one-hot encoding)\n",
    "categorical_encoder = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
    "categorical_feature_names = categorical_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = list(numerical_feature_names) + list(categorical_feature_names)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf_pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Top 15 Feature Importances', fontsize=16)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4g5h6i7j8k9l0m1n2o3p4q5r6s7t8u9v0w1x2y3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- recommendation system implementation ----------\n",
    "def generate_recommendations(patient_data, model_pipeline):\n",
    "    \"\"\"\n",
    "    Generate personalized healthcare recommendations based on patient data.\n",
    "    \n",
    "    Parameters:\n",
    "    patient_data (dict): Dictionary containing patient information\n",
    "    model_pipeline: Trained model pipeline\n",
    "    \n",
    "    Returns:\n",
    "    dict: Recommendation and confidence score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert patient data to DataFrame\n",
    "    patient_df = pd.DataFrame([patient_data])\n",
    "    \n",
    "    # Apply the same preprocessing as training data\n",
    "    patient_df.columns = patient_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "    \n",
    "    # Extract vital signs if present\n",
    "    if 'vital_signs' in patient_df.columns:\n",
    "        vital_data = patient_df['vital_signs'].apply(extract_vital_signs)\n",
    "        patient_df['systolic_bp'] = [x[0] for x in vital_data]\n",
    "        patient_df['diastolic_bp'] = [x[1] for x in vital_data]\n",
    "        patient_df['heart_rate'] = [x[2] for x in vital_data]\n",
    "    \n",
    "    # Create age group\n",
    "    if 'age' in patient_df.columns:\n",
    "        patient_df['age_group'] = pd.cut(patient_df['age'], \n",
    "                                        bins=[0, 30, 45, 60, 100], \n",
    "                                        labels=['Young Adult', 'Middle Adult', 'Older Adult', 'Senior'])\n",
    "    \n",
    "    # Create chronic condition indicator\n",
    "    if 'medical_history' in patient_df.columns:\n",
    "        patient_df['has_chronic_condition'] = patient_df['medical_history'].str.lower().apply(\n",
    "            lambda x: any(condition in str(x) for condition in chronic_conditions)\n",
    "        ).astype(int)\n",
    "    \n",
    "    # Create family history indicator\n",
    "    if 'family_history' in patient_df.columns:\n",
    "        patient_df['family_history_indicator'] = (patient_df['family_history'] == 'Yes').astype(int)\n",
    "    \n",
    "    # Select the same features used in training\n",
    "    patient_features = patient_df[feature_columns]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model_pipeline.predict(patient_features)[0]\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = model_pipeline.predict_proba(patient_features)[0]\n",
    "    confidence = np.max(probabilities)\n",
    "    \n",
    "    # Map predictions to recommendations\n",
    "    recommendation_mapping = {\n",
    "        'Excellent': 'Continue current treatment plan. Patient is responding very well.',\n",
    "        'Good': 'Current treatment is effective. Consider minor adjustments if needed.',\n",
    "        'Fair': 'Treatment response is moderate. Consider alternative approaches or additional interventions.',\n",
    "        'Poor': 'Treatment response is suboptimal. Recommend immediate consultation and treatment plan revision.'\n",
    "    }\n",
    "    \n",
    "    recommendation = recommendation_mapping.get(prediction, 'No specific recommendation available.')\n",
    "    \n",
    "    return {\n",
    "        'predicted_response': prediction,\n",
    "        'recommendation': recommendation,\n",
    "        'confidence': confidence\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g4h5i6j7k8l9m0n1o2p3q4r5s6t7u8v9w0x1y2z3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- test recommendation system ----------\n",
    "# Example patient data\n",
    "example_patients = [\n",
    "    {\n",
    "        'age': 45,\n",
    "        'gender': 'Male',\n",
    "        'ethnicity': 'Caucasian',\n",
    "        'medical_history': 'Hypertension, Diabetes',\n",
    "        'family_history': 'Yes',\n",
    "        'vital_signs': 'BP: 130/85, HR: 72',\n",
    "        'recovery_time': 14\n",
    "    },\n",
    "    {\n",
    "        'age': 62,\n",
    "        'gender': 'Female',\n",
    "        'ethnicity': 'Asian',\n",
    "        'medical_history': 'Heart Disease',\n",
    "        'family_history': 'No',\n",
    "        'vital_signs': 'BP: 118/75, HR: 68',\n",
    "        'recovery_time': 10\n",
    "    },\n",
    "    {\n",
    "        'age': 34,\n",
    "        'gender': 'Male',\n",
    "        'ethnicity': 'Hispanic',\n",
    "        'medical_history': 'Asthma',\n",
    "        'family_history': 'Yes',\n",
    "        'vital_signs': 'BP: 122/80, HR: 75',\n",
    "        'recovery_time': 18\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== PERSONALIZED HEALTHCARE RECOMMENDATIONS ===\\n\")\n",
    "\n",
    "for i, patient in enumerate(example_patients, 1):\n",
    "    print(f\"Patient {i}:\")\n",
    "    print(f\"  Age: {patient['age']}\")\n",
    "    print(f\"  Gender: {patient['gender']}\")\n",
    "    print(f\"  Medical History: {patient['medical_history']}\")\n",
    "    print(f\"  Vital Signs: {patient['vital_signs']}\")\n",
    "    \n",
    "    # Generate recommendation\n",
    "    result = generate_recommendations(patient, rf_pipeline)\n",
    "    \n",
    "    print(f\"\\n  Predicted Treatment Response: {result['predicted_response']}\")\n",
    "    print(f\"  Recommendation: {result['recommendation']}\")\n",
    "    print(f\"  Confidence: {result['confidence']:.2%}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4i5j6k7l8m9n0o1p2q3r4s5t6u7v8w9x0y1z2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- save the model ----------\n",
    "import joblib\n",
    "\n",
    "# Save the trained model pipeline\n",
    "model_path = Path('../models/healthcare_recommendation_model.pkl')\n",
    "model_path.parent.mkdir(exist_ok=True)\n",
    "joblib.dump(rf_pipeline, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save feature columns for future use\n",
    "feature_info = {\n",
    "    'feature_columns': feature_columns,\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features\n",
    "}\n",
    "feature_path = Path('../models/feature_info.pkl')\n",
    "joblib.dump(feature_info, feature_path)\n",
    "print(f\"Feature information saved to: {feature_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i4j5k6l7m8n9o0p1q2r3s4t5u6v7w8x9y0z1a2b3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've successfully implemented a personalized healthcare recommendation system:\n",
    "\n",
    "### Key Accomplishments:\n",
    "1. **Data Exploration**: Analyzed patient demographics, medical conditions, and treatment responses\n",
    "2. **Feature Engineering**: Extracted numerical values from vital signs and created new features\n",
    "3. **Model Development**: Built a Random Forest classifier to predict treatment responses\n",
    "4. **Model Evaluation**: Achieved good accuracy with detailed performance metrics\n",
    "5. **Recommendation System**: Created a system that generates personalized healthcare recommendations\n",
    "6. **Model Deployment**: Saved the trained model for future use\n",
    "\n",
    "### Healthcare Applications:\n",
    "- Treatment response prediction\n",
    "- Personalized care plan development\n",
    "- Clinical decision support\n",
    "- Patient risk stratification\n",
    "\n",
    "### Next Steps:\n",
    "1. Deploy the model as a web application\n",
    "2. Integrate with electronic health records (EHR) systems\n",
    "3. Continuously update the model with new patient data\n",
    "4. Expand to include more health conditions and treatment options\n",
    "\n",
    "This system can help healthcare providers make more informed decisions and offer personalized recommendations to improve patient outcomes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
